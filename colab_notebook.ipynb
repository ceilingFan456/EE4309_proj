{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE4309 Object Detectation Project - Google Colab Version\n",
    "\n",
    "This notebook maintains the same experience as the local Makefile commands, allowing you to easily run the project on Colab.\n",
    "\n",
    "## üìù Important Notes\n",
    "1. **Enable GPU**: Click `Runtime` ‚Üí `Change runtime type` ‚Üí Select `T4 GPU`\n",
    "2. **Run Order**: Please run cells in sequence\n",
    "3. **Command Mapping**: Each cell corresponds to a make command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 0: Clone Project and Enter Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Enderfga/EE4309_proj.git\n",
    "%cd EE4309_proj\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup (equivalent to `make setup`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install project dependencies (equivalent to make setup)\n",
    "!pip install -q -r requirements.txt -e .\n",
    "\n",
    "# Verify environment\n",
    "import torch\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Help (equivalent to `make help`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all available commands (equivalent to make help)\n",
    "!make help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Step 2: Download Samples (equivalent to `make samples`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample images (equivalent to make samples)\n",
    "!make samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 3: Train Model (equivalent to `make train`)\n",
    "\n",
    "**Note**: On Colab, consider using fewer epochs to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard training (equivalent to make train)\n",
    "# model choices: \"reset50\", \"vit\"\n",
    "!make train BATCH_SIZE=1 EPOCHS=20 MODEL=\"reset50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 4: Evaluate Model (equivalent to `make eval`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model (equivalent to make eval)\n",
    "!make eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 5: Run Inference (equivalent to `make infer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference (equivalent to make infer)\n",
    "!make infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Submit Your Work (equivalent to `make submit`)\n",
    "\n",
    "**Important**: This will create a git commit with your student information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit your work with student information (equivalent to make submit)\n",
    "# You will be prompted to enter:\n",
    "# - Your full name\n",
    "# - Your student ID (format: A0123456X)\n",
    "# - Optional additional message\n",
    "# Please run this command before compressing and submitting your project.\n",
    "!make submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Extra: Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to save training results\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create save directory\n",
    "!mkdir -p /content/drive/MyDrive/EE4309_results\n",
    "\n",
    "# Copy training results\n",
    "!cp -r runs/* /content/drive/MyDrive/EE4309_results/\n",
    "print(\"‚úÖ Results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualize Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "# Detection result images to display\n",
    "detection_images = [\n",
    "    'runs/infer_vis/dog_det.jpg',\n",
    "    'runs/infer_vis/eagle_det.jpg', \n",
    "    'runs/infer_vis/horses_det.jpg',\n",
    "    'runs/infer_vis/person_det.jpg'\n",
    "]\n",
    "\n",
    "# Check which images exist\n",
    "existing_images = [img for img in detection_images if os.path.exists(img)]\n",
    "\n",
    "if len(existing_images) >= 4:\n",
    "    print(\"Displaying inference detection results:\")\n",
    "    \n",
    "    # Create 2x2 grid\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Object Detection Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Flatten axes for easy iteration\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(existing_images[:4]):\n",
    "        try:\n",
    "            img = mpimg.imread(img_path)\n",
    "            axes_flat[i].imshow(img)\n",
    "            # Extract image name without extension for title\n",
    "            img_name = os.path.basename(img_path).replace('_det.jpg', '')\n",
    "            axes_flat[i].set_title(img_name.title(), fontsize=14)\n",
    "            axes_flat[i].axis('off')\n",
    "        except Exception as e:\n",
    "            axes_flat[i].text(0.5, 0.5, f'Error loading\\n{os.path.basename(img_path)}', \n",
    "                            ha='center', va='center', transform=axes_flat[i].transAxes)\n",
    "            axes_flat[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "elif len(existing_images) > 0:\n",
    "    print(f\"Found {len(existing_images)} detection results:\")\n",
    "    \n",
    "    # Calculate grid size for available images\n",
    "    n_images = len(existing_images)\n",
    "    n_cols = min(2, n_images)\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(8*n_cols, 6*n_rows))\n",
    "    fig.suptitle('Available Detection Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Handle single image case\n",
    "    if n_images == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes if hasattr(axes, '__iter__') else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(existing_images):\n",
    "        try:\n",
    "            img = mpimg.imread(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            img_name = os.path.basename(img_path).replace('_det.jpg', '')\n",
    "            axes[i].set_title(img_name.title(), fontsize=14)\n",
    "            axes[i].axis('off')\n",
    "        except Exception as e:\n",
    "            axes[i].text(0.5, 0.5, f'Error loading\\n{os.path.basename(img_path)}', \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(n_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No detection result images found.\")\n",
    "    print(\"Please run inference first:\")\n",
    "    print(\"!make infer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Check Git History (View Submission Records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View git commit history to check submissions\n",
    "!git log --oneline -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View detailed changes in the last commit\n",
    "!git diff HEAD~1 --stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Troubleshooting\n",
    "\n",
    "### 1. GPU Out of Memory\n",
    "```bash\n",
    "# Reduce batch size\n",
    "!bash scripts/train.sh --batch-size 64 --epochs 20\n",
    "```\n",
    "\n",
    "### 2. Runtime Limits\n",
    "- Colab free tier has ~12 hour limit\n",
    "- Use checkpoint feature to train in segments\n",
    "- Save to Google Drive regularly\n",
    "\n",
    "### 3. Disconnection Issues\n",
    "- Use resume training feature above to continue\n",
    "- Consider Colab Pro for longer runtime\n",
    "\n",
    "### 4. Submission Issues\n",
    "- Make sure you run `make submit` before the deadline\n",
    "- Use `git log` to verify your submission was recorded\n",
    "- Your instructor can use `git diff` to review your changes"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ee4309-frcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
